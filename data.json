{
  "papers": [
    {
      "id": "https://arxiv.org/pdf/2403.12122.pdf",
      "paragraphs": [
        {
          "source": "The dispersal of a primordial planetesimal disk drives orbital evolution among the rest of the giant planets as well. In Table 3, we list key parameters in the final architectures of the giant planets after 4 Gyrs of evolution. In the first column we list the ratio of Saturn’s to Jupiter’s orbital period. In the real solar system, this ratio is ∼2.48, but our final simulated systems have a range of ratios spanning from 2.1–2.7, with a median value of 2.39. Although the locations of various secular resonances depend on this exact ratio, this has dynamical consequences primarily for the inner solar system rather than the Kuiper belt (e.g. Brasser et al. 2009; Walsh & Morbidelli 2011; Clement et al. 2020).  However, the Kuiper belt’s architecture is dependent upon the ratio of Neptune’s to Uranus’ orbital period, and we list these final ratios for our systems in the second column of Table 3. In our original simulations, all but one system (2500Pb) evolved above a period ratio of 2. Values in these original systems ranged from 1.97– 2.31, with a median of 2.13. Consulting a large number of ∼1000-particle simulations from prior works (Clement et al. 2018, 2021c,a), we find roughly half of all 4-planet instability outcomes finish with a Neptune-to-Uranus period ratio of under 2, so it is not clear whether this is an unrealized systematic issue with our particular 5-planet resonant chain or whether it is simply an issue of bad luck among our 12 simulated systems. Nevertheless, the crossing of Uranus and Neptune’s 2:1 MMR can destabilize much of the resonant Kuiper belt population, limiting the utility of our simulation results, and is therefore a poor feature for simulations meant to study Kuiper belt formation (Graham & Volk 2024).",
          "translations": [
            {
              "id": "source",
              "content": "The dispersal of a primordial planetesimal disk drives orbital evolution among the rest of the giant planets as well. In Table 3, we list key parameters in the final architectures of the giant planets after 4 Gyrs of evolution. In the first column we list the ratio of Saturn’s to Jupiter’s orbital period. In the real solar system, this ratio is ∼2.48, but our final simulated systems have a range of ratios spanning from 2.1–2.7, with a median value of 2.39. Although the locations of various secular resonances depend on this exact ratio, this has dynamical consequences primarily for the inner solar system rather than the Kuiper belt (e.g. Brasser et al. 2009; Walsh & Morbidelli 2011; Clement et al. 2020).  However, the Kuiper belt’s architecture is dependent upon the ratio of Neptune’s to Uranus’ orbital period, and we list these final ratios for our systems in the second column of Table 3. In our original simulations, all but one system (2500Pb) evolved above a period ratio of 2. Values in these original systems ranged from 1.97– 2.31, with a median of 2.13. Consulting a large number of ∼1000-particle simulations from prior works (Clement et al. 2018, 2021c,a), we find roughly half of all 4-planet instability outcomes finish with a Neptune-to-Uranus period ratio of under 2, so it is not clear whether this is an unrealized systematic issue with our particular 5-planet resonant chain or whether it is simply an issue of bad luck among our 12 simulated systems. Nevertheless, the crossing of Uranus and Neptune’s 2:1 MMR can destabilize much of the resonant Kuiper belt population, limiting the utility of our simulation results, and is therefore a poor feature for simulations meant to study Kuiper belt formation (Graham & Volk 2024)."
            },
            {
              "id": "simplify-and-improve.ts",
              "content": "The scattering of a primitive disk of planetesimals causes changes in the orbits of the giant planets. In Table 3, we present important parameters regarding the final arrangements of the giant planets after 4 billion years of evolution. The first column shows the ratio of Saturn's orbital period to Jupiter's. In our solar system, this ratio is approximately 2.48, but in our simulated systems, the ratios range from 2.1 to 2.7, with a median value of 2.39. The exact ratio affects the positions of certain resonances, primarily impacting the inner solar system rather than the Kuiper belt. The architecture of the Kuiper belt, on the other hand, is influenced by the ratio of Neptune's to Uranus' orbital periods, which we list in the second column of Table 3. In our initial simulations, all systems except one (2500Pb) evolved with a period ratio above 2, ranging from 1.97 to 2.31, with a median of 2.13. Looking at previous studies with around 1000 particles, we see that about half of the outcomes with 4-planet instabilities end with a Neptune-to-Uranus period ratio below 2. It is unclear if this discrepancy is due to a flaw in our specific 5-planet resonant chain or if it is simply a result of chance in our 12 simulated systems. However, the crossing of Uranus and Neptune's 2:1 resonance can disrupt much of the resonant Kuiper belt population, which limits the usefulness of our simulation results for studying Kuiper belt formation."
            }
          ]
        }
      ]
    },
    {
      "id": "https://arxiv.org/pdf/2403.12183.pdf",
      "paragraphs": [
        {
          "source": "We study the robustness of stable matchings with respect to arbitrary, possibly minimal, perturbations. Such perturbations may arise in both decentralized and centralized settings.  Over time, participants’ preferences may shift, market composition may change, or matched participants might end their partnerships. For instance, in labor markets, a family shock may generate new geographical preferences for workers; new positions may appear and workers may either become available or retire; an employer and an employee might mutually agree to terminate the employment relationship. While the set of stable matchings may also be altered by such changes, they could all lead to instability. In particular, some participants that should be paired under current market conditions might be mismatched or unmatched. In some situations, decentralized interactions cannot break certain partnerships. Imagine a two-sided market divided into two submarkets, New York and Los Angeles, in which every Angeleno prefers any Angeleno to any New Yorker, and vice versa. Suppose that the New York submarket has a unique stable matching and the Los Angeles submarket has two stable matchings. The entire market naturally has two stable matchings as well. If all Angelenos are paired in accordance with one of the two stable matchings for the Los Angeles submarket, and therefore for the entire market, decentralized interactions cannot unmatch any such pair of matched Angelenos. As a result, the stabilization dynamics cannot attain another stable matching in the entire market. Here, Angelenos can be matched in a stable way inside the group so that every insider prefers her stable partner to anyone outside Los Angeles. We call such a group a fragment. In this example, New Yorkers form a fragment as well. A fragment is trivial if all stable matchings in the entire market match participants inside the fragment in the same way. In particular, Angelenos constitute a non-trivial fragment, while New Yorkers form a trivial fragment.  If a market has a non-trivial fragment, some unstable matchings cannot yield certain stable matchings. Theorem 1 shows that the reverse is also true. When there are no nontrivial fragments, any unstable matching can yield any stable matching through decentralized interactions. Non-trivial fragments are the only restraints on the stabilization dynamics. The absence of non-trivial fragments is a mild condition: simulations suggest that they are rare in large random markets. Thus, in most markets, the decentralized process is fluid enough to attain any stable matching.  Theorem 1 suggests one type of fragility of stable matchings. A small perturbation of a stable matching may culminate in any stable matching, close to or distant from the original stable matching. The celebrated Deferred Acceptance mechanism of Gale and Shapley (1962), which is used to match doctors to hospitals and students to schools, aims at implementing an extremal stable matching, the best stable matching for one market side, doctors and students, respectively. Our results imply that any perturbation of such a clearinghouse’s outcome need not revert back to the intended extremal stable matching; decentralized interactions can instead lead to the other extremal stable matching, or anything in between.",
          "translations": [
            {
              "id": "Improve the comprehensibility of the following passage.",
              "content": "We are examining how stable matchings can be affected by small changes, whether they are decentralized or centralized. These changes can happen when people's preferences shift, the market changes, or when partnerships end. These changes can lead to instability in the set of stable matchings, causing some participants to be mismatched or unmatched. In some cases, decentralized interactions cannot break certain partnerships. For example, in a market with two submarkets, New York and Los Angeles, where participants strongly prefer those from their own city, stable matchings can be affected. If all participants from Los Angeles are matched according to one stable matching, decentralized interactions cannot change these matches. This creates what we call a \"fragment,\" where participants are matched in a stable way within their group. Non-trivial fragments, where stable matchings within the fragment differ, can limit the stabilization process. However, simulations show that these are rare in large random markets, allowing decentralized processes to achieve any stable matching. Our findings suggest that stable matchings can be fragile, as small changes can lead to different stable matchings. The Deferred Acceptance mechanism, used in matching doctors and students to hospitals and schools, aims to achieve the best stable matching. However, our results show that even small changes to this mechanism can lead to different stable matchings, rather than reverting back to the original one."
            },
            {
              "id": "simplify-and-improve.ts",
              "content": "We are examining how stable matchings hold up against various changes, even small ones. These changes can happen in both decentralized and centralized settings. Over time, people's preferences may shift, the makeup of the market may change, or matched individuals may end their partnerships. For example, in job markets, a family event could cause workers to prefer different locations, new job openings may arise, or employees and employers may decide to part ways. While these changes can alter the set of stable matchings, they could also lead to instability. Some participants who should be matched may end up mismatched or unmatched. In certain situations, decentralized interactions may not be able to break certain partnerships.\n\nConsider a market divided into two submarkets, New York and Los Angeles, where individuals in each submarket prefer their own kind over the other. If the New York submarket has one stable matching and the Los Angeles submarket has two, then the entire market has two stable matchings as well. If all individuals in Los Angeles are matched according to one of the stable matchings, decentralized interactions cannot break those matches. This means that the stabilization process cannot reach a different stable matching for the entire market. In this case, individuals in Los Angeles form a non-trivial fragment, while those in New York form a trivial fragment.\n\nIf a market has a non-trivial fragment, certain unstable matchings cannot lead to specific stable matchings. Conversely, Theorem 1 shows that when there are no non-trivial fragments, any unstable matching can lead to any stable matching through decentralized interactions. Non-trivial fragments are the only obstacles to the stabilization process. However, simulations suggest that non-trivial fragments are rare in large random markets, meaning that in most cases, the decentralized process can achieve any stable matching.\n\nTheorem 1 highlights a vulnerability of stable matchings. A small change to a stable matching can result in any stable matching, whether close to or far from the original one. The Deferred Acceptance mechanism, used in matching doctors to hospitals and students to schools, aims to implement the best stable matching for one side of the market. Our findings suggest that even a slight change to the outcome of this mechanism may not necessarily lead back to the intended best stable matching; decentralized interactions could instead result in a different stable matching, or something in between."
            }
          ]
        }
      ]
    },
    {
      "id": "https://arxiv.org/pdf/2403.12147.pdf",
      "paragraphs": [
        {
          "source": "When electrons move in a crystal lattice comprised of oppositely charged ions they create lattice distortions (phonons) in their neighbourhoods, which back-react on the electrons via the polarization they carry. This results in each electron being accompanied by a cloud of phonons lowering its mobility. Such a composite object is called a polaron; when several electrons are considered we speak of multi-polarons. In [Frö54], H. Fröhlich introduced a Hamiltonian governing the dynamics of multi-polarons. In his model the electrons are treated as non-relativistic quantum mechanical particles without spin degrees of freedom whereas the phonons, which can be created and annihilated along the time evolution, are described by a non-relativistic bosonic quantum field.  Starting with the seminal work of Feynman [Fey55], one main technique in the investigation of polaron models has been functional integration, both in theoretical physics and mathematics. Shortly, in Section 1.3, we shall give numerous references to mathematical papers exploiting various Feynman–Kac formulas for vacuum expectation values of members of the semigroup generated by Fröhlich’s Hamiltonian.  Building on recent mathematical studies of Feynman–Kac formulas in non- and semi-relativistic quantum field theory [GMM17, MM18, Mat21, HM23a], we devote this article to the derivation of Feynman–Kac formulas in Fröhlich’s multipolaron model for semigroup members applied to arbitrary vectors in the underlying Hilbert space. Since electrons interact via repulsive Coulomb potentials and polarons exposed to external electric and magnetic fields are often treated – see [AG14, Gha21, GW13, Löw88] for mathematical results on polarons in magnetic fields – we shall in fact work under almost optimal conditions on the electrostatic potential and optimal conditions on the magnetic vector potential still permitting to define the Hamiltonian via semibounded quadratic forms. In some articles, the electrons are confined to open regions of Euclidean space [AL13, FLST11], for technical reasons at least, and sometimes both the electrons and the phonons are confined [FS21, BM23]. Therefore, we shall work under general hypotheses on the electron-phonon interaction covering the latter two situations as well as the original Fröhlich model.  Together with the inequalities established in this article, our Feynman–Kac formulas can form the basis for further studies of the semigroup and ground state eigenvectors (if any) in polaron models in analogy to the theory of magnetic Schrödinger semigroups [BHL00, Sim82] and its extensions to the related Pauli–Fierz model of non-relativistic quantum electrodynamics [Mat16] and Nelson’s model for nucleonmeson interactions [MM18, HM22]",
          "translations": [
            {
              "id": "source",
              "content": "When electrons move in a crystal lattice comprised of oppositely charged ions they create lattice distortions (phonons) in their neighbourhoods, which back-react on the electrons via the polarization they carry. This results in each electron being accompanied by a cloud of phonons lowering its mobility. Such a composite object is called a polaron; when several electrons are considered we speak of multi-polarons. In [Frö54], H. Fröhlich introduced a Hamiltonian governing the dynamics of multi-polarons. In his model the electrons are treated as non-relativistic quantum mechanical particles without spin degrees of freedom whereas the phonons, which can be created and annihilated along the time evolution, are described by a non-relativistic bosonic quantum field.  Starting with the seminal work of Feynman [Fey55], one main technique in the investigation of polaron models has been functional integration, both in theoretical physics and mathematics. Shortly, in Section 1.3, we shall give numerous references to mathematical papers exploiting various Feynman–Kac formulas for vacuum expectation values of members of the semigroup generated by Fröhlich’s Hamiltonian.  Building on recent mathematical studies of Feynman–Kac formulas in non- and semi-relativistic quantum field theory [GMM17, MM18, Mat21, HM23a], we devote this article to the derivation of Feynman–Kac formulas in Fröhlich’s multipolaron model for semigroup members applied to arbitrary vectors in the underlying Hilbert space. Since electrons interact via repulsive Coulomb potentials and polarons exposed to external electric and magnetic fields are often treated – see [AG14, Gha21, GW13, Löw88] for mathematical results on polarons in magnetic fields – we shall in fact work under almost optimal conditions on the electrostatic potential and optimal conditions on the magnetic vector potential still permitting to define the Hamiltonian via semibounded quadratic forms. In some articles, the electrons are confined to open regions of Euclidean space [AL13, FLST11], for technical reasons at least, and sometimes both the electrons and the phonons are confined [FS21, BM23]. Therefore, we shall work under general hypotheses on the electron-phonon interaction covering the latter two situations as well as the original Fröhlich model.  Together with the inequalities established in this article, our Feynman–Kac formulas can form the basis for further studies of the semigroup and ground state eigenvectors (if any) in polaron models in analogy to the theory of magnetic Schrödinger semigroups [BHL00, Sim82] and its extensions to the related Pauli–Fierz model of non-relativistic quantum electrodynamics [Mat16] and Nelson’s model for nucleonmeson interactions [MM18, HM22]"
            },
            {
              "id": "simplify-and-improve.ts",
              "content": "When electrons move through a crystal lattice made up of oppositely charged ions, they cause distortions in the lattice structure, known as phonons, in their surrounding areas. These phonons interact with the electrons, affecting their movement by carrying a certain polarization. This interaction results in the formation of a composite object called a polaron, where each electron is surrounded by a cloud of phonons that reduce its mobility. When multiple electrons are involved, they form multi-polarons. H. Fröhlich introduced a Hamiltonian in 1954 to describe the dynamics of multi-polarons. In this model, electrons are treated as non-relativistic quantum particles without spin, while phonons are described as a non-relativistic bosonic quantum field that can be created and destroyed over time.\n\nFunctional integration, introduced by Feynman in 1955, has been a key technique in studying polaron models in both theoretical physics and mathematics. This article focuses on deriving Feynman-Kac formulas in Fröhlich's multipolaron model for semigroup members applied to arbitrary vectors in the underlying Hilbert space. The study builds on recent mathematical research on Feynman-Kac formulas in quantum field theory and aims to provide a basis for further exploration of the semigroup and ground state eigenvectors in polaron models.\n\nThe article considers the interaction of electrons via repulsive Coulomb potentials and the effects of external electric and magnetic fields on polarons. The study works under optimal conditions on the electrostatic and magnetic potentials, allowing for the definition of the Hamiltonian through semibounded quadratic forms. Various mathematical results on polarons in magnetic fields are also referenced.\n\nThe research covers different scenarios, including electrons confined to open regions of Euclidean space and situations where both electrons and phonons are confined. The study establishes general hypotheses on the electron-phonon interaction, encompassing a range of scenarios from the original Fröhlich model to more complex configurations. The derived Feynman-Kac formulas, along with the inequalities established in the article, serve as a foundation for further investigations into polaron models, similar to the study of magnetic Schrödinger semigroups and related models in non-relativistic quantum electrodynamics and nucleon-meson interactions."
            }
          ]
        }
      ]
    },
    {
      "id": "https://arxiv.org/pdf/2403.12869.pdf",
      "paragraphs": [
        {
          "source": "In this work, we conducted an independent evaluation of Spider-style [33] strategy discovery and schedule creation. Focusing on the FOF fragment of the TPTP library, we collected over a thousand Vampire proving strategies, each a priori optimized to perform well on a single problem. Using these strategies, it is easy to construct a single monolithic schedule which covers most of the problems known to be solvable within the budget used by the CASC competition. This suggests that for CASC not to be mainly a competition in memorization, using a substantial set of previously unseen problems each year is essential.  To construct strong schedules using the discovered strategies, we proposed a greedy schedule construction procedure, which can compete with optimal approaches. For a time budget of approximately 2 minutes, the greedy algorithm takes less than a minute to produce a schedule that solves more than 99.0 % as many problems as an optimal schedule, which takes more than 16 hours to generate. For shorter time budgets, optimal schedule construction is no longer feasible, while greedy construction still produces relatively strong schedules.  This surprising strength of the greedy scheduler can be further reinforced by various regularization mechanisms, which constitute the main contribution of this work. An appropriately chosen regularization allows us to outperform the optimal schedule on unseen problems. Finally, the runtime speed and simplicity of the greedy schedule construction algorithm and the regularization techniques make them attractive for reuse and further experimentation.",
          "translations": [
            {
              "id": "source",
              "content": "In this work, we conducted an independent evaluation of Spider-style [33] strategy discovery and schedule creation. Focusing on the FOF fragment of the TPTP library, we collected over a thousand Vampire proving strategies, each a priori optimized to perform well on a single problem. Using these strategies, it is easy to construct a single monolithic schedule which covers most of the problems known to be solvable within the budget used by the CASC competition. This suggests that for CASC not to be mainly a competition in memorization, using a substantial set of previously unseen problems each year is essential.  To construct strong schedules using the discovered strategies, we proposed a greedy schedule construction procedure, which can compete with optimal approaches. For a time budget of approximately 2 minutes, the greedy algorithm takes less than a minute to produce a schedule that solves more than 99.0 % as many problems as an optimal schedule, which takes more than 16 hours to generate. For shorter time budgets, optimal schedule construction is no longer feasible, while greedy construction still produces relatively strong schedules.  This surprising strength of the greedy scheduler can be further reinforced by various regularization mechanisms, which constitute the main contribution of this work. An appropriately chosen regularization allows us to outperform the optimal schedule on unseen problems. Finally, the runtime speed and simplicity of the greedy schedule construction algorithm and the regularization techniques make them attractive for reuse and further experimentation."
            },
            {
              "id": "simplify-and-improve.ts",
              "content": "In this study, we evaluated the Spider-style strategy discovery and schedule creation independently. We focused on the FOF fragment of the TPTP library and gathered over a thousand Vampire proving strategies, each optimized to perform well on a specific problem. By using these strategies, we were able to create a single schedule that covers most solvable problems within the budget of the CASC competition. This highlights the importance of using new problems each year to prevent the competition from being based solely on memorization.\n\nTo create strong schedules using the discovered strategies, we developed a greedy schedule construction procedure that can rival optimal approaches. In just under a minute, the greedy algorithm can produce a schedule that solves over 99.0% of the problems that an optimal schedule, taking over 16 hours to generate, can solve within a 2-minute time budget. Even with shorter time budgets, the greedy construction method still produces effective schedules.\n\nThe surprising effectiveness of the greedy scheduler can be enhanced further by incorporating various regularization mechanisms, which are the main focus of this study. By selecting the right regularization, we were able to outperform the optimal schedule on new problems. The speed and simplicity of the greedy schedule construction algorithm, along with the regularization techniques, make them appealing for future use and experimentation."
            }
          ]
        }
      ]
    },
    {
      "id": "https://arxiv.org/pdf/2403.12768.pdf",
      "paragraphs": [
        {
          "source": "To encourage divergent thinking and foster customization, educators can further generate variant scripts and utilize alternative prompts, expanding the possibilities for tailoring the output content to specific learning objectives. Upon selecting an item in the Stickers panel, the current prompt associated with the chosen sticker is displayed in the Refine panel. Educators can edit the prompt and regenerate stickers to better fit the intended context, while simultaneously mitigating the risk of generating potentially inappropriate content.  Moreover, by leveraging varied themes and contexts, educators can create more engaging learning contents that not only reinforce vocabulary acquisition but also promote linguistic adaptability, as shown in Fig. 4. By offering a diverse array of learning materials, educators can stimulate more dynamic forms of vocabulary engagement and deepen learners’ connections with the language.",
          "translations": [
            {
              "id": "source",
              "content": "To encourage divergent thinking and foster customization, educators can further generate variant scripts and utilize alternative prompts, expanding the possibilities for tailoring the output content to specific learning objectives. Upon selecting an item in the Stickers panel, the current prompt associated with the chosen sticker is displayed in the Refine panel. Educators can edit the prompt and regenerate stickers to better fit the intended context, while simultaneously mitigating the risk of generating potentially inappropriate content.  Moreover, by leveraging varied themes and contexts, educators can create more engaging learning contents that not only reinforce vocabulary acquisition but also promote linguistic adaptability, as shown in Fig. 4. By offering a diverse array of learning materials, educators can stimulate more dynamic forms of vocabulary engagement and deepen learners’ connections with the language."
            },
            {
              "id": "simplify-and-improve.ts",
              "content": "To encourage creative thinking and allow for personalization, educators can create different scripts and use alternative prompts to customize the content to specific learning goals. When a sticker is selected in the Stickers panel, the corresponding prompt appears in the Refine panel. Educators can modify the prompt and generate new stickers to better suit the context, while also reducing the risk of inappropriate content. By incorporating various themes and contexts, educators can develop more interesting learning materials that enhance vocabulary acquisition and encourage flexibility in language use, as illustrated in Fig. 4. Providing a variety of learning resources can inspire more interactive vocabulary learning and strengthen students' connection with the language."
            }
          ]
        }
      ]
    }
  ]
}
